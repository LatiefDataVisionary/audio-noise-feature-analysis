{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqvPmXyD0fRTANT0TME8G0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LatiefDataVisionary/audio-noise-feature-analysis/blob/main/notebooks/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "793b229b"
      },
      "source": [
        "# **High-Level Feature Analysis of Environmental Noise**\n",
        "\n",
        "## **1. Project Setup and Initialization**\n",
        "\n",
        "### **1.1 Introduction**\n",
        "\n",
        "This project aims to analyze and visualize high-level audio features, specifically Spectrogram and Chroma Features, extracted from a dataset of 10 different environmental noise types. This analysis serves as a Capstone project for the \"High Level Speech Feature\" course provided by BISA AI Academy. The dataset used is the \"Audio Noise Dataset\" sourced from Kaggle, containing various types of environmental noise in `.webm` format. The goal is to demonstrate how these features can help differentiate between distinct sound sources visually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0af3c7d7"
      },
      "source": [
        "### **1.2 Library Installation and Imports**\n",
        "\n",
        "We will begin by installing and importing the necessary Python libraries for audio processing, visualization, and file handling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18c3173e"
      },
      "source": [
        "# Install necessary libraries\n",
        "# !pip install librosa matplotlib numpy seaborn ffmpeg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5078046"
      },
      "source": [
        "# Import necessary libraries\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import subprocess\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "333f206e"
      },
      "source": [
        "### **1.3 Mounting Google Drive**\n",
        "\n",
        "The dataset is assumed to be stored in Google Drive. We will mount Google Drive to access the audio files. Please ensure your dataset is located in the specified path within your Drive.\n",
        "\n",
        "Dataset Link: https://drive.google.com/drive/folders/1UXBlA2QRT6jaidknV9t7R7a7LGQjwdNt?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f825ac18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a3f3a2-6fdd-40a4-a6e6-3d4e0c7c1a74"
      },
      "source": [
        "# Mount Google Drive to access the dataset\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f447465"
      },
      "source": [
        "### **1.4 Path and Constant Definition**\n",
        "\n",
        "Define the paths for the raw dataset in Google Drive and the directory where converted audio files will be stored. We will also create the output directory if it doesn't exist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18ad1722",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d734dc-b1d3-462a-b51a-5a746d119c74"
      },
      "source": [
        "# Define paths\n",
        "DRIVE_DATASET_PATH = '/content/drive/MyDrive/Dataset/Audio Noise Dataset Myanmar/'\n",
        "PROCESSED_DATA_PATH = 'processed_audio'\n",
        "\n",
        "# Create the processed audio directory if it doesn't exist\n",
        "if not os.path.exists(PROCESSED_DATA_PATH):\n",
        "    os.makedirs(PROCESSED_DATA_PATH)\n",
        "    print(f\"Created directory: {PROCESSED_DATA_PATH}\")\n",
        "else:\n",
        "    print(f\"Directory already exists: {PROCESSED_DATA_PATH}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created directory: processed_audio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2c69137"
      },
      "source": [
        "## **2. Data Pre-processing: Audio Format Conversion**\n",
        "\n",
        "### **2.1 The Need for Conversion**\n",
        "\n",
        "Audio files in the original dataset are in the `.webm` format. While this format is common, the `librosa` library, which is essential for our feature extraction tasks, works optimally with more standard audio formats like `.wav`. Therefore, we need to convert the `.webm` files to `.wav` format before proceeding with the analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd9f0666"
      },
      "source": [
        "### **2.2 Conversion Script**\n",
        "\n",
        "This script will scan the specified Google Drive directory for `.webm` files and convert each one to a `.wav` file with a sample rate of 22050 Hz and a single audio channel (mono). The converted files will be saved in the `processed_audio` directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b71f7a6",
        "outputId": "12ef327e-231b-4f3b-ee2d-d712cdbffc03"
      },
      "source": [
        "webm_files = glob.glob(os.path.join(DRIVE_DATASET_PATH, '*.webm'))\n",
        "converted_count = 0\n",
        "\n",
        "for webm_file in webm_files:\n",
        "    file_name = os.path.basename(webm_file)\n",
        "    base_name, _ = os.path.splitext(file_name)\n",
        "    wav_file = os.path.join(PROCESSED_DATA_PATH, f\"{base_name}.wav\")\n",
        "\n",
        "    if not os.path.exists(wav_file):\n",
        "        print(f\"Converting {file_name} to {base_name}.wav...\")\n",
        "        try:\n",
        "            # Use ffmpeg to convert webm to wav\n",
        "            subprocess.run([\n",
        "                'ffmpeg', '-i', webm_file,\n",
        "                '-ar', '22050',  # Set sample rate to 22050 Hz\n",
        "                '-ac', '1',      # Set audio channels to 1 (mono)\n",
        "                wav_file\n",
        "            ], check=True, capture_output=True, text=True)\n",
        "            converted_count += 1\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Error converting {file_name}: {e.stderr}\")\n",
        "    else:\n",
        "        print(f\"{base_name}.wav already exists. Skipping conversion.\")\n",
        "\n",
        "if converted_count > 0:\n",
        "    print(\"Conversion process finished.\")\n",
        "else:\n",
        "    print(\"No new files to convert or all files already exist.\")\n",
        "\n",
        "print(\"All files processed.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting sample-1 a crowded place.webm to sample-1 a crowded place.wav...\n",
            "Converting sample-2 urban areas with people talking.webm to sample-2 urban areas with people talking.wav...\n",
            "Converting sample-8 a working place.webm to sample-8 a working place.wav...\n",
            "Converting sample-3 the restaurant.webm to sample-3 the restaurant.wav...\n",
            "Converting sample-10 motorbike and people talking .webm to sample-10 motorbike and people talking .wav...\n",
            "Converting sample-9 a festival.webm to sample-9 a festival.wav...\n",
            "Converting sample-7 the rainy day.webm to sample-7 the rainy day.wav...\n",
            "Converting sample-6 painful sounds.webm to sample-6 painful sounds.wav...\n",
            "Converting sample-4 mosquitos .webm to sample-4 mosquitos .wav...\n",
            "Converting sample-5 car traffic.webm to sample-5 car traffic.wav...\n",
            "Conversion process finished.\n",
            "All files processed.\n"
          ]
        }
      ]
    }
  ]
}